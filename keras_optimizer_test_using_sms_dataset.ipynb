{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 4248 2021-2022 \n",
    "## les membres du groupe\n",
    "- fezeu Ghomsi Eugene Clotaire 17Q2864 \n",
    "- Nono Mabou Wilfried Brondon 21S2817 brondonnono3@gmail.com\n",
    "- NGBAYAFOU NGOUH Ch√©ripha Cheriphalynette@gmail.com\n",
    "- Junior Libii junior.libii@facsciences-uy1.cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## binary naive bayes classification on sms dataset\n",
    "on s'interesse ici a la presence ou l'abscende d'un mot dans corpus pour pour determiner si c'est un spam ou un ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "import getpass\n",
    "filepath = ''\n",
    "REPOPATH = 'fez2000/TP_4248.git'\n",
    "FILENAME= 'spam.csv'\n",
    "HOST='github.com'\n",
    "if path.exists(f'./{FILENAME}'):\n",
    "    filepath = f'./{FILENAME}'\n",
    "elif path.exists(f'./datas/{FILENAME}'):\n",
    "    filepath = f'./datas/{FILENAME}'\n",
    "else:\n",
    "    filepath = f'./datas/{FILENAME}'\n",
    "    def load_from_git():\n",
    "        def clone(): \n",
    "            GIT_PATH = f'https://{HOST}/{REPOPATH}' \n",
    "            !git clone {GIT_PATH} 'temp'\n",
    "        def clone_by_token():\n",
    "            GIT_TOKEN= getpass.getpass(\"votre token git\") \n",
    "            GIT_PATH = f'https://{GIT_TOKEN}@{HOST}/{REPOPATH}' \n",
    "            !git clone {GIT_PATH} 'temp'\n",
    "        def clone_by_username_and_password():\n",
    "            GIT_USER_NAME= getpass.getpass(\"votre nom d'utilisateur git\")\n",
    "            GIT_PASSWORD= getpass.getpass(\"votre mot de pass git\")\n",
    "            GIT_PATH = f'https://{GIT_USER_NAME}:{GIT_PASSWORD}@{HOST}/{REPOPATH}'\n",
    "            !git  clone  {GIT_PATH} 'temp' \n",
    "        if not path.exists(f'./temp/datas/{FILENAME}'):\n",
    "            try:\n",
    "                clone()\n",
    "            except e:\n",
    "                pass\n",
    "        if not path.exists(f'./temp/datas/{FILENAME}'):\n",
    "            try:\n",
    "                clone_by_username_and_password()\n",
    "            except e:\n",
    "                pass\n",
    "        if not path.exists(f'./temp/datas/{FILENAME}'):\n",
    "            try:\n",
    "                clone_by_token()\n",
    "            except e:\n",
    "                pass\n",
    "        if not path.exists(f'./temp/datas/{FILENAME}'):     \n",
    "            load_from_git()\n",
    "        else:\n",
    "            %cd './temp'\n",
    "\n",
    "    load_from_git()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /home/eugene/anaconda3/lib/python3.9/site-packages (6.4.1)\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipykernel) (7.29.0)\n",
      "Requirement already satisfied: traitlets<6.0,>=4.1.0 in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipykernel) (5.1.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipykernel) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipykernel) (0.1.2)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipykernel) (1.4.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipykernel) (6.1.12)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipykernel) (6.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel) (0.18.0)\n",
      "Requirement already satisfied: decorator in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel) (5.1.0)\n",
      "Requirement already satisfied: pickleshare in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel) (3.0.20)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel) (4.8.0)\n",
      "Requirement already satisfied: pygments in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel) (2.10.0)\n",
      "Requirement already satisfied: backcall in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/eugene/anaconda3/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel) (58.0.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/eugene/anaconda3/lib/python3.9/site-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/eugene/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel) (22.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/eugene/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /home/eugene/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel) (4.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/eugene/anaconda3/lib/python3.9/site-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/eugene/anaconda3/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/eugene/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel) (1.16.0)\n",
      "Installed kernelspec venv in /home/eugene/.local/share/jupyter/kernels/venv\n",
      "Requirement already satisfied: gensim in /home/eugene/anaconda3/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/eugene/anaconda3/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/eugene/anaconda3/lib/python3.9/site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/eugene/anaconda3/lib/python3.9/site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: seaborn in /home/eugene/anaconda3/lib/python3.9/site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/eugene/anaconda3/lib/python3.9/site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/eugene/anaconda3/lib/python3.9/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/eugene/anaconda3/lib/python3.9/site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/eugene/anaconda3/lib/python3.9/site-packages (from seaborn) (1.20.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/eugene/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/eugene/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/eugene/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/eugene/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/eugene/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: six in /home/eugene/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/eugene/anaconda3/lib/python3.9/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: pandas in /home/eugene/anaconda3/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/eugene/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/eugene/anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/eugene/anaconda3/lib/python3.9/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/eugene/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/eugene/anaconda3/lib/python3.9/site-packages (1.20.3)\n",
      "Requirement already satisfied: bs4 in /home/eugene/anaconda3/lib/python3.9/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/eugene/anaconda3/lib/python3.9/site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/eugene/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: BeautifulSoup4 in /home/eugene/anaconda3/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/eugene/anaconda3/lib/python3.9/site-packages (from BeautifulSoup4) (2.2.1)\n",
      "Requirement already satisfied: lxml in /home/eugene/anaconda3/lib/python3.9/site-packages (4.6.3)\n",
      "Requirement already satisfied: nltk in /home/eugene/anaconda3/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: click in /home/eugene/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/eugene/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/eugene/anaconda3/lib/python3.9/site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /home/eugene/anaconda3/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "/home/eugene/anaconda3/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading collection 'all-nltk'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /home/eugene/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all-nltk\n",
      "Requirement already satisfied: tqdm in /home/eugene/anaconda3/lib/python3.9/site-packages (4.62.3)\n",
      "Collecting multiprocessing\n",
      "  Using cached multiprocessing-2.6.2.1.tar.gz (108 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/eugene/anaconda3/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-qsqem0_5/multiprocessing_4bded29bb6a34c9f8f2701c0c669ff5e/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-qsqem0_5/multiprocessing_4bded29bb6a34c9f8f2701c0c669ff5e/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-_x7hlmrp\n",
      "         cwd: /tmp/pip-install-qsqem0_5/multiprocessing_4bded29bb6a34c9f8f2701c0c669ff5e/\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-qsqem0_5/multiprocessing_4bded29bb6a34c9f8f2701c0c669ff5e/setup.py\", line 94\n",
      "        print 'Macros:'\n",
      "              ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print('Macros:')?\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b8/8a/38187040f36cec8f98968502992dca9b00cc5e88553e01884ba29cbe6aac/multiprocessing-2.6.2.1.tar.gz#sha256=ef3b81ad85d7de252e5491b1daac028e17f9741cbe3625032e6eaa4ad4c79900 (from https://pypi.org/simple/multiprocessing/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Using cached multiprocessing-2.6.1.1.zip (129 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/eugene/anaconda3/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-qsqem0_5/multiprocessing_df7d85663c534427a15b3f655ea6927f/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-qsqem0_5/multiprocessing_df7d85663c534427a15b3f655ea6927f/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-__q2wa2g\n",
      "         cwd: /tmp/pip-install-qsqem0_5/multiprocessing_df7d85663c534427a15b3f655ea6927f/\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-qsqem0_5/multiprocessing_df7d85663c534427a15b3f655ea6927f/setup.py\", line 94\n",
      "        print 'Macros:'\n",
      "              ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print('Macros:')?\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/98/7f/4967a994241802fcbb37204e424bd34fc4b239372dcea2f48cd2ffb0859f/multiprocessing-2.6.1.1.zip#sha256=c2f4b019ffcb72ea1a58c940f4500fba388d0a00d2b51bafc8fb11df5b85519c (from https://pypi.org/simple/multiprocessing/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Using cached multiprocessing-2.6.1.1.tar.gz (106 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/eugene/anaconda3/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-qsqem0_5/multiprocessing_a4dc78462f334f968c5206b979413278/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-qsqem0_5/multiprocessing_a4dc78462f334f968c5206b979413278/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-5zogm7oj\n",
      "         cwd: /tmp/pip-install-qsqem0_5/multiprocessing_a4dc78462f334f968c5206b979413278/\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-qsqem0_5/multiprocessing_a4dc78462f334f968c5206b979413278/setup.py\", line 94\n",
      "        print 'Macros:'\n",
      "              ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print('Macros:')?\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/68/08/b7c8b11f1265263e8bb525f0cd3c6747802bea087aac54469f0bef286524/multiprocessing-2.6.1.1.tar.gz#sha256=ad576359eda273ddbbbc0df9678df6ba653dee06dfe97839190826ec3f70c5ab (from https://pypi.org/simple/multiprocessing/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Using cached multiprocessing-2.6.0.2.tar.gz (103 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/eugene/anaconda3/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-qsqem0_5/multiprocessing_abe4a321eefd4524afbf3afdb9ac5c3c/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-qsqem0_5/multiprocessing_abe4a321eefd4524afbf3afdb9ac5c3c/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-7jmysa37\n",
      "         cwd: /tmp/pip-install-qsqem0_5/multiprocessing_abe4a321eefd4524afbf3afdb9ac5c3c/\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-qsqem0_5/multiprocessing_abe4a321eefd4524afbf3afdb9ac5c3c/setup.py\", line 79\n",
      "        print 'Macros:'\n",
      "              ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print('Macros:')?\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/71/63/591f4ae9ed88570b04b39d1fbd523a2bd88a1a38685927ff25df9af1b379/multiprocessing-2.6.0.2.tar.gz#sha256=461a1998428ac4335cc4141223e362295e1032a689faf04acd3375eea8c0b6bd (from https://pypi.org/simple/multiprocessing/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement multiprocessing (from versions: 2.6.0-0.1, 2.6.0.2, 2.6.1.1, 2.6.2.1)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for multiprocessing\u001b[0m\n",
      "Requirement already satisfied: keras in /home/eugene/anaconda3/lib/python3.9/site-packages (2.8.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement textfixtures (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for textfixtures\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --user ipykernel\n",
    "!python -m ipykernel install --user --name=venv\n",
    "!pip install gensim\n",
    "!pip install seaborn\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install bs4\n",
    "!pip install BeautifulSoup4\n",
    "!pip install lxml\n",
    "!pip install nltk\n",
    "!python -m nltk.downloader all-nltk\n",
    "!pip install tqdm\n",
    "!pip install keras\n",
    "!pip install textfixtures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                             corpus\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6    ham  Even my brother is not like to speak with me. ...\n",
       "7    ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "dataset = pd.read_csv(filepath, encoding=\"ISO-8859-1\", usecols=['v1', 'v2'], dtype={'v1':str,'v2':str})\n",
    "dataset = dataset.dropna(how=\"any\")\n",
    "dataset.rename(columns={'v2':'corpus', \"v1\": \"target\"}, inplace=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86961"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['corpus'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on a 86961  words, c'est un petit dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugene/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt_pro = dataset['target'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.9)\n",
    "plt.ylabel('Nombre d\\'occurence', fontsize=12)\n",
    "plt.xlabel('Messages', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing\n",
    "\n",
    "Below we define a function to convert text to lower-case and strip punctuation/symbols from words and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def cleanText(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
    "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "    text = text.lower()\n",
    "    text = text.replace('x', '')\n",
    "    return text\n",
    "dataset['corpus'] = dataset['corpus'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is that seriously how you spell his name?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['corpus'][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split of 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "train = pd.DataFrame(train)\n",
    "test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['corpus']), tags=[r.target]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['corpus']), tags=[r.target]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what a training entry looks like - an example complaint narrative tagged by 'Credit reporting'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['as', 'valued', 'customer', 'am', 'pleased', 'to', 'advise', 'you', 'that', 'following', 'recent', 'review', 'of', 'your', 'mob', 'no', 'you', 'are', 'awarded', 'with', '√•¬£1500', 'bonus', 'prize', 'call', '09066364589'], tags=['spam'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged.values[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We'll instantiate a Doc2Vec model-Distributed Bag of Words (DBOW). In the Word2Vec architecture, the two algorithm names are ‚Äúcontinuous bag of words‚Äù (cbow) and ‚Äúskip-gram‚Äù (sg); in the Doc2Vec architecture, the corresponding algorithms are ‚Äúdistributed bag of words‚Äù (dbow) and ‚Äúdistributed memory‚Äù (dm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBOW\n",
    "\n",
    "DBOW is the Doc2Vec model analogous to Skip-gram model in Word2Vec. The paragraph vectors are obtained by training a neural network on the task of predicting a probability distribution of words in a paragraph given a randomly-sampled word from the paragraph.\n",
    "\n",
    "Training a Doc2Vec model is rather straight forward in Gensim, we initialize the model and train for 30 epochs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the minimum word count to 2 in order to discard words with very few occurrences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1799140.52it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=1, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 990420.54it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1092266.67it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1108626.61it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 946193.06it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1126026.41it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1071517.46it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1128356.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 709511.41it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1133831.40it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1096145.92it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1067113.68it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 789544.63it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1862437.16it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1122934.41it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1068926.72it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1066348.47it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1085885.93it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1077943.04it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1063505.99it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1071026.36it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1864347.57it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1883452.57it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1828502.75it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1567438.25it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1147351.17it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1825034.65it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1019049.69it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1132261.76it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 2099844.11it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 759132.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 1.96 s, total: 14.8 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buliding the final vector feature for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, epochs=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugene/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.9515550239234449\n",
      "Testing F1 score: 0.9508204584375209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Memory with Averaging\n",
    "\n",
    "Distributed Memory (DM) acts as a memory that remembers what is missing from the current context‚Ää‚Äî‚Ääor as the topic of the paragraph. While the word vectors represent the concept of a word, the document vector intends to represent the concept of a document.\n",
    "We again instantiate a Doc2Vec model with a vector size with 300 words and iterating over the training corpus 30 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 999925.77it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=5, negative=1, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1076595.08it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 2015250.17it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1106003.08it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1055613.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1046027.98it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1154314.13it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1147592.65it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1095485.24it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1072430.71it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1847502.33it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1078938.43it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 2072704.71it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1898095.34it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 666494.95it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1841885.55it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 2064334.38it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 694627.61it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1170503.44it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1152362.49it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1171593.30it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1078227.25it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1143901.09it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1141347.03it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 2047026.10it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1079365.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1148882.26it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1149851.37it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1064405.62it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1367479.15it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3900/3900 [00:00<00:00, 1815917.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.2 s, sys: 4.96 s, total: 31.1 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.9623205741626795\n",
      "Testing F1 score: 0.9624292662574295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugene/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'testfixtures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18943/1007273012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_doc2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConcatenatedDoc2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenatedDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_dbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dmm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gensim/test/test_doc2vec.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtestfixtures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog_capture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'testfixtures'"
     ]
    }
   ],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = get_vectors(new_model, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.6778572623828648\n",
      "Testing F1 score: 0.664561533967402\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
